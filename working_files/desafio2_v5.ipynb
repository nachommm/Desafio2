{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Desafio 2 - Machine Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Grupo 7</h3>\n",
    "<ul>\n",
    "    <li>Ignacio Mendieta</li>\n",
    "    <li>Laura Jazmín Chao</li>\n",
    "    <li>Juan Nicolás Capistrano</li>\n",
    "    <li>Betiana Srur</li>\n",
    "    <li>Marecelo Carrizo</li>\n",
    "    \n",
    "</ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Objetivo</h4>\n",
    "Aplicar las ténicas de Machine Learning sobre el dataset de Properati para calcular automáticamente el precio por metro cuadrado de las propiedades. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_toc\"></a> \n",
    "<h2> Tabla de Contenidos </h2>\n",
    "\n",
    "[Librerías](#section_import)\n",
    "\n",
    "[Dataset](#section_dataset)\n",
    "\n",
    "[Selección de los datos](#section_selection)\n",
    "\n",
    "[Limpieza de datos](#section_limpieza)\n",
    "\n",
    "[Imputación de datos faltantes](#section_imput)\n",
    "\n",
    "$\\hspace{.5cm}$[Imputamos datos de <strong>surface</strong>](#section_surface)\n",
    "\n",
    "$\\hspace{.5cm}$[Imputamos datos de <strong>price_usd_per_m2</strong>](#section_price)\n",
    "\n",
    "$\\hspace{.5cm}$[Creación de datos para imputación de rooms](#section_categories)\n",
    "       \n",
    "[Extracción de datos de <strong>description</strong>](#section_description)   \n",
    "    \n",
    "$\\hspace{.5cm}$[Cantidad de ambientes](#section_amb)\n",
    "\n",
    "$\\hspace{.5cm}$[Amenities](#section_caba_description_amenities)\n",
    "    \n",
    "[Creación de dummies sobre datos catgóricos](#section_dummies)\n",
    "    \n",
    "[Mapa de correlación de datos cuantitativos](#section_corrheatmap)   \n",
    "    \n",
    "[Modelos de Regresión](#section_model)\n",
    "    \n",
    "$\\hspace{.5cm}$[Primeras pruebas](#section_test1)  \n",
    "    \n",
    "$\\hspace{.5cm}$[Pruebas con Lasso](#section_test_lasso1)  \n",
    "\n",
    "[Definición de Outliers](#section_outliers)  \n",
    "\n",
    "[Pruebas con datos ajustados](#section_test2)\n",
    "\n",
    "$\\hspace{.5cm}$[Pruebas Modelo Lasso](#section_test_lasso2)\n",
    "\n",
    "$\\hspace{.5cm}$[Pruebas con modelo Ridge](#section_test_ridge)\n",
    "\n",
    "$\\hspace{.5cm}$[Pruebas con modelo Elastic](#section_test_elastic)\n",
    "\n",
    "[Creación de features para complejizar el modelo](#section_new_features)\n",
    "\n",
    "$\\hspace{1.cm}$[Superficie2](#section_sup2)\n",
    "\n",
    "$\\hspace{1.cm}$[Superficie3](#section_sup3)\n",
    "\n",
    "[Estimación de precio total utilizando el mismo modelo](#section_total_price_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Checklist </h3>\n",
    "\n",
    "<h4> De los datos filtrados según Desafio 1 deberiamos:</h4>\n",
    "\n",
    "<font color='red'>OK</font>  1. Terminar de dropear variables incompletas que serian necesarias para poder entrenar un modelo. (ejemplo: si la propiedad no posee: price, price_aprox_local_currency,price_usd_per_m2, price_per_m2, etc...) la información de los barrios ya fue analizado y dropeado en el paso anterior.\n",
    "\n",
    "<font color='red'>OK</font> 2. Definir las variables CUANTITATIVAS, ejemplo precio, total de m2 de superficie.\n",
    "\n",
    "<font color='red'>OK</font> 3. Armar las variables CUALITATIVAS, Dummy (ejemplo: place_name, property_type, amenities, rooms).\n",
    "\n",
    "<font color='red'>OK</font> 4. Armar una nueva variable Dummy que contemple los precios de propiedad segun su distribución por metro cuadrado. Utilizando Panda CUT.\n",
    "\n",
    "5. Arreglar la columna rooms para que se pueda usar como numérica en los modelos\n",
    "\n",
    "\n",
    "<h4> Finalizado el analisis de datos, armamos diferentes modelos para predecir el precio de la propiedad</h4>\n",
    "\n",
    "<font color='red'>OK</font> 1. Regresion Lineal Multiple\n",
    "\n",
    "<font color='red'>OK</font> 2. Entrenar los modelos con Lasso, RidgeCV y utilizando Cross Validation.\n",
    "\n",
    "3. Cambiar los hiperparámetros en Ridge y Lasso???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_import\"></a> \n",
    "<h3>Librerías</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Librería Grafica.\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Opciones de visualización de columnas y filas al ejecutar las celdas\n",
    "pd.set_option('display.max_columns', 100) # Para mostrar todas las columnas\n",
    "pd.set_option('display.max_rows', 100) # Para mostrar todas las filas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_dataset\"></a> \n",
    "<h3>Dataset</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la ruta de la información.\n",
    "data_propiedades = \"Data/properati.csv\"\n",
    "\n",
    "# Leemos los datos del archivo\n",
    "data = pd.read_csv(data_propiedades, sep=\",\", encoding=\"UTF-8\")\n",
    "\n",
    "# Chequeamos que los datos se hayan importado correctamente\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chequeamos cantidad de registros y cantidad de columnas\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_selection\"></a> \n",
    "<h3>Selección de los datos</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a los análisis previos realizados sobre el Dataset, tomaremos los datos de CABA únicamente para realizar un modelo de machine learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una máscara y la aplicamos al dataframe anterior para traer los registros que necesitamos\n",
    "data_caba_mask = data.state_name == 'Capital Federal' \n",
    "data_caba = data.loc[data_caba_mask, :]\n",
    "\n",
    "# Chequeamos cómo quedaron los datos\n",
    "data_caba.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_dataset_nulos\"></a> \n",
    "<h4>Cálculo de cantidad de nulos</h4>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculamos cantidad de nulos por campo\n",
    "# data_caba.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculamos porcentaje de nulos por campo\n",
    "#  print(np.round((100 * cant_nulos_por_campo / data_caba.shape[0]),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Distribución de <strong>property_type</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos cantidad de valores de cada elemento en property_type y operation para ver distribución\n",
    "property_type_count = data_caba.property_type.value_counts()\n",
    "print(f'property_type: \\n{property_type_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convertimos el count anterior en las categorías del gráfico\n",
    "# categories = np.array(property_type_count.index)\n",
    "\n",
    "# cord_x = data_caba.property_type.value_counts() / data_caba.shape[0]\n",
    "# palette = ['#440154', '#29788E', '#22A784', '#FDE724']\n",
    "\n",
    "# p = figure(x_range=categories, plot_width=500, plot_height=200)\n",
    "# p.vbar(x=categories, top=cord_x, width=0.6,\n",
    "#        color=palette)\n",
    "\n",
    "# p.yaxis.formatter = NumeralTickFormatter(format='0 %')\n",
    "# output_notebook(resources=INLINE)\n",
    "# show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Distribución de <strong>currency</strong></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba.currency.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Distribución de <strong>barrio</strong></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_name_count = data_caba.place_name.value_counts()\n",
    "# place_name_count.sort_index()\n",
    "# place_name_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_limpieza\"></a> \n",
    "<h3>Limpieza de datos</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_dataset_drop\"></a> \n",
    "<h4> Drop de columnas innecesarias </h4>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las columnas que en esta instancia no aportan datos útiles para el modelo predictivo que queremos crear. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la lista de columnas a filtrar\n",
    "drop_columns = ['Unnamed: 0', 'operation', 'place_with_parent_names', 'country_name', 'state_name', 'geonames_id', 'lat-lon','lat', 'lon', \n",
    "                'floor', 'expenses','properati_url','title', 'image_thumbnail']\n",
    "\n",
    "data_caba_clean = data_caba.drop(drop_columns, axis=1)\n",
    "# data_caba_clean.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3> Limpiamos <strong>currency</strong> </h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una mask para traer los valores en monedas que no son USD ni ARS.\n",
    "currency_OTHER_CURRENCY_mask = (data_caba_clean.currency == 'PEN') | (data_caba_clean.currency == 'UYU')\n",
    "# Observamos esos registros\n",
    "data_caba_clean.loc[currency_OTHER_CURRENCY_mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos drop de esos registros y chequeamos la diferencia entre cantidad original y actual\n",
    "cant_registros = data_caba_clean.shape[0]\n",
    "# Dropeamos las moneda PEN y UYU ## OJO la moneda UYU era de una propiedad en Mendoza.\n",
    "data_caba_clean.drop(data_caba_clean.loc[currency_OTHER_CURRENCY_mask, :].index, inplace = True) \n",
    "# Verificamos.\n",
    "print(f'Cantidad de registros original - registro actuales: {cant_registros - data_caba_clean.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Limpiamos <strong>place_name</strong> </h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una mascara y dropeamos los de 'Capital Federal'\n",
    "capi_mask = data_caba_clean.place_name == 'Capital Federal'\n",
    "data_caba_clean.drop(data_caba_clean.loc[capi_mask, :].index, inplace=True)\n",
    "\n",
    "# Chequeamos cómo quedaron los datos\n",
    "data_caba_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Volvemos a calcular cantidad de nulos luego de eliminar columnas y registros sin barrio específico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos cantidad de nulos por campo\n",
    "data_caba_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos porcentaje de nulos por campo\n",
    "print(np.round((100 * data_caba_clean.isnull().sum() / data_caba_clean.shape[0]),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_caba_clean.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Eliminamos registros según un umbral de datos faltantes </h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos los registros donde no haya por lo menos 10 campos completos. \n",
    "\n",
    "umbral = 10\n",
    "data_caba_clean.dropna(axis = 0, thresh=umbral, inplace=True)\n",
    "\n",
    "display(data_caba_clean.shape)\n",
    "# Se pierden 3500 datos aprox (ver shape de abajo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos cómo quedaron los datos de precio que nos importan\n",
    "mask_price_validation = data_caba_clean.price != data_caba_clean.price_aprox_usd\n",
    "display(data_caba_clean.loc[mask_price_validation, :].shape)\n",
    "\n",
    "\n",
    "# display(data_caba_clean.loc[mask_price_validation, :].head(30))\n",
    "# data_caba_clean.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_imput\"></a> \n",
    "<h3>Imputación de datos faltantes</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero realizamos ciertas verificaciones de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Verificamos que el price y el price_aprox_usd sean los mismos, y luego si fuera así dropeamos uno de los dos y utilizamos el otro como target\n",
    "\n",
    "mask_price_validation = data_caba_clean.price != data_caba_clean.price_aprox_usd\n",
    "\n",
    "display(data_caba_clean.loc[mask_price_validation, :].shape)\n",
    "\n",
    "# Detectamos que hay 1131 propiedades donde los valores son diferentes? pero estan en Pesos o son NaN?\n",
    "\n",
    "display(data_caba_clean.loc[mask_price_validation, :].sample(10))\n",
    "\n",
    "# Detectamos que tenemos los dos casos, donde los precios son NaN y donde la moneda está en ARS (lo cual no estaría mal)\n",
    "# En el caso de ARS, vemos que el valor de price toma el de la moneda local ~ Por lo que podriamos llegar a eliminar price, currency y price_aprox_local_currency \n",
    "\n",
    "# Para los valores de NaN tendriamos que tomar la decisión si los dropeamos o tratamos de calcular un precio promedio en base a la cantidad de metros cuadrados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_surface\"></a> \n",
    "<h3> Completamos datos faltantes de superficie </h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para la superficie de metros cuadadros totales, podemos creer que en caso de ser Nan \n",
    "# es porque es un departamente sin balcon y la cantidad de m2 cubierta sería iguala la cantidad de m2 totales.data_caba\n",
    "\n",
    "data_caba_clean.surface_total_in_m2.fillna(data_caba_clean.surface_covered_in_m2 + (data_caba_clean.surface_covered_in_m2 * 0.10), inplace=True)\n",
    "\n",
    "# data_caba_clean.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idem al punto anterior pero ahora de surface_total a surface_covered\n",
    "\n",
    "data_caba_clean.surface_covered_in_m2.fillna(data_caba_clean.surface_total_in_m2, inplace=True)\n",
    "\n",
    "# data_caba_clean.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_price\"></a> \n",
    "<h3> Completamos datos faltantes de price_usd_per_m2 </h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idem al punto anterior pero ahora calculamos el precio por metro cuadrado.\n",
    "\n",
    "data_caba_clean.price_usd_per_m2.fillna(data_caba_clean.price_aprox_usd / data_caba_clean.surface_total_in_m2, inplace=True)\n",
    "\n",
    "data_caba_clean.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Eliminamos columnas de precios en moneda local </h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropeamos los valores que sabemos que está repetidos o con otra moneda.data_caba\n",
    "\n",
    "data_caba_clean.drop(columns=['price', 'currency','price_per_m2', 'price_aprox_local_currency'], inplace=True)\n",
    "\n",
    "data_caba_clean.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Nuevo recuento de nulos </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nPorcentaje de valores incompletos por columna:')\n",
    "print(f'{round(100 * data_caba_clean.isnull().sum()/data_caba_clean.shape[0], 2)}')\n",
    "\n",
    "display(data_caba_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_categories\"></a> \n",
    "<h3>Creación de datos para imputación de <strong>rooms<strong/></h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delimitamos los bins para realizar un cut\n",
    "# bins = [20, 30, 45, 75, 150, 220]\n",
    "bins = [0, 30, 45, 75, 150, 220, 500]\n",
    "labels = ['mono', 's45', 's75', 's150', 's220', 's500' ]\n",
    "\n",
    "data_caba_clean['m2_categories'] = pd.cut(data_caba_clean.surface_covered_in_m2, bins, labels)\n",
    "data_caba_clean['m2_labels'] = pd.cut(x=data_caba_clean.surface_covered_in_m2, bins=bins, labels=labels, right=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean.m2_categories.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean.m2_labels.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_description\"></a> \n",
    "<h3> Extracción de datos del campo <strong>description</strong></h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalización del campo para que sea todo minúscula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pasamos todos los string de la columna a minúscula para que las expresiones regulares no necesiten contener las dos formas\n",
    "data_caba_clean.description = data_caba_clean.description.str.lower()\n",
    "\n",
    "data_caba_clean.description.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_amb\"></a> \n",
    "<h4> Cantidad de ambientes</h4>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos expresiones regulares y las buscamos en el campo descripción, luego asiganmos los valores encontrados a columnas nuevas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amb_pattern = \"((?P<numero_amb>\\d)(\\s)?(amb|anv|amv|anb))\"\n",
    "amb_pattern_regex = re.compile(amb_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amb_match = data_caba_clean.description.apply(lambda x: x if (x is np.NaN) | (x is None) else\\\n",
    "                                      amb_pattern_regex.search(x))\n",
    "mask_amb_match_notnull = amb_match.notnull()\n",
    "\n",
    "# Aplicamos el grupo que encuentra el dígito de cantidad de ambientes, casteado como integer\n",
    "data_caba_clean.loc[mask_amb_match_notnull, 'number_rooms'] = \\\n",
    "amb_match.loc[mask_amb_match_notnull].apply(lambda x: int(x.group(\"numero_amb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dorm_pattern = \"((?P<numero_dorm>\\d)(\\s)?(dorm))\"\n",
    "dorm_pattern_regex = re.compile(dorm_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dorm_match = data_caba_clean.description.apply(lambda x: x if (x is np.NaN) | (x is None) else dorm_pattern_regex.search(x))\n",
    "\n",
    "mask_dorm_match_notnull = dorm_match.notnull()\n",
    "\n",
    "data_caba_clean.loc[mask_dorm_match_notnull, 'number_rooms'] = \\\n",
    "dorm_match.loc[mask_dorm_match_notnull].apply(lambda x: int(x.group(\"numero_dorm\"))+1)\n",
    "\n",
    "#se asume que el numero de ambientes es numero_dorm +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamos de llenar los rooms que faltan con lo que obtuvimos de la descripción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de nulos que quedan en 'rooms'\n",
    "data_caba_clean.rooms.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de datos que obtuvimos de la descripción\n",
    "data_caba_clean.number_rooms.notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean.rooms.fillna(data_caba_clean.number_rooms, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean.rooms.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamos de llenar los rooms que faltan con los datos de las categorías creadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una serie donde el index son las categorias y los valores son la cantidad de ambientes estimados\n",
    "room_index = [\"mono\", \"s45\", \"s75\", \"s150\", \"s220\", 's500']\n",
    "room_values = [1,2,3,4,5,10]\n",
    "rooms_series = pd.Series(room_values,index=room_index, dtype=int)\n",
    "rooms_series.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_room_null = data_caba_clean.rooms.isnull()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean.loc[mask_room_null, 'rooms'] = data_caba_clean.m2_labels.loc[mask_room_null].apply(rooms_series)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean.rooms.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_caba_clean.rooms.fillna(data_caba_clean.rooms_upon_categories, inplace=True)\n",
    "data_caba_clean.rooms.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos qué superficies tienen los registros donde room == null \n",
    "mask_room_null = data_caba_clean.rooms.isnull()\n",
    "data_room_null = data_caba_clean.loc[mask_room_null, 'surface_covered_in_m2']\n",
    "\n",
    "# plt.hist(data_room_null, bins=40, rwidth=0.8, color = '#29788E')\n",
    "# plt.xlabel = 'Superficie cubierta'\n",
    "# plt.ylabel = 'Count'\n",
    "# plt.show()\n",
    "\n",
    "data_room_null.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos la columna que ya no vamos a utilizar\n",
    "data_caba_clean.drop(columns=['number_rooms'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos los registros que quedan ya que corresponden a data extrema\n",
    "data_caba_clean.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos los datos de ambientes a numérico nuevamente para poder usarlo como variable\n",
    "data_caba_clean.rooms = data_caba_clean.rooms.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_caba_description_amenities\"></a> \n",
    "<h4> Amenities</h4>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Pileta </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pileta_pattern = \"(?P<pileta>pileta|piscina|picina|pisina|pool)\"\n",
    "pileta_pattern_regex = re.compile(pileta_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pileta_match = data_caba_clean.description.apply(lambda x: x if (x is np.NaN) | (x is None) else\\\n",
    "                                      pileta_pattern_regex.search(x))\n",
    "mask_pileta_match_notnull = pileta_match.notnull()\n",
    "\n",
    "data_caba_clean.loc[mask_pileta_match_notnull, 'pool'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_caba_clean['pool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean['pool'].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Completamos los datos NaN con ceros (convertimos en una variable dummy)\n",
    "data_caba_clean.pool.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Laundry </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laudry_pattern = \"(?P<laundry>laundry|lavadero)\"\n",
    "laundry_pattern_regex = re.compile(laudry_pattern)\n",
    "\n",
    "laundry_match = data_caba_clean.description.apply(lambda x: x if (x is np.NaN) | (x is None) else\\\n",
    "                                      laundry_pattern_regex.search(x))\n",
    "mask_laundry_match_notnull = laundry_match.notnull()\n",
    "\n",
    "data_caba_clean.loc[mask_laundry_match_notnull, 'laundry'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean['laundry'].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean.laundry.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Parking </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_pattern = \"(?P<parking>parking|estacionamiento|garage|cochera|garaje)\"\n",
    "parking_pattern_regex = re.compile(parking_pattern)\n",
    "\n",
    "parking_match = data_caba_clean.description.apply(lambda x: x if (x is np.NaN) | (x is None) else\\\n",
    "                                      parking_pattern_regex.search(x))\n",
    "mask_parking_match_notnull = parking_match.notnull()\n",
    "\n",
    "data_caba_clean.loc[mask_parking_match_notnull, 'parking'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean['parking'].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean.parking.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Gimnasio </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_pattern = \"(?P<gimnasio>gim|gym|fitness|fitnes|ejercicio)\"\n",
    "gym_pattern_regex = re.compile(gym_pattern)\n",
    "\n",
    "gym_match = data_caba_clean.description.apply(lambda x: x if (x is np.NaN) | (x is None) else\\\n",
    "                                      gym_pattern_regex.search(x))\n",
    "mask_gim_match_notnull = gym_match.notnull()\n",
    "\n",
    "data_caba_clean.loc[mask_gim_match_notnull, 'gym'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean['gym'].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean.gym.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_dummies\"></a> \n",
    "<h3> Creación dummies sobre datos categóricos </h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos la función get_dummies con one-hot encoding (drop_first=True) para todas las variables que necesitamos\n",
    "property_type_dummies = pd.get_dummies(data_caba_clean['property_type'], drop_first = True, prefix='prop_type')\n",
    "property_type_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_labels_dummies = pd.get_dummies(data_caba_clean['m2_labels'], drop_first = True, prefix='m2_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_name_dummies = pd.get_dummies(data_caba_clean['place_name'], drop_first = True, prefix='place_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_dummies = pd.get_dummies(data_caba_clean['rooms'], drop_first = True, prefix = 'rooms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un join para concatenar las columnas al dataframe\n",
    "data_caba_clean = data_caba_clean.join([property_type_dummies,m2_labels_dummies, place_name_dummies,rooms_dummies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos el archivo para usar en otras notebooks, esto lo guarda en el mismo directorio en el que estamos operando\n",
    "# data_caba_clean.to_csv('data_caba_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_corrheatmap\"></a> \n",
    "<h3>Mapa de correlación de varaibles cuantitativas</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_caba_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caba_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['price_aprox_usd', 'surface_total_in_m2','surface_covered_in_m2', \n",
    "        'price_usd_per_m2', 'rooms','pool', 'laundry', 'parking', 'gym']\n",
    "#Mapa de correlación\n",
    "\n",
    "g = plt.figure(figsize=(13,10))\n",
    "g = sns.heatmap(data_caba_clean[cols].corr(),annot=True, cmap=\"YlGnBu\")\n",
    "g.set_xticklabels(data_caba_clean[cols].columns, rotation=30)\n",
    "plt.title(\"Mapa de calor de correlación entre variables\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_model\"></a> \n",
    "<h3>Modelos de Regresión Lineal</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerías de machine learning\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para realizar el entrenamiento con un set de testeo.\n",
    "\n",
    "# Visualización de datos predichos para incluir en las funciones\n",
    "def graf_lineal_model(X, y, y_pred):\n",
    "    # Graficamos el modelo\n",
    "    plt.scatter(y_pred, y, s=30, alpha=0.4, c='b')\n",
    "    plt.plot(y,y, '-.',c='g')\n",
    "    plt.show()\n",
    "    print(y.shape)\n",
    "    print(y_pred.shape)\n",
    "    return\n",
    "\n",
    "#Modelo de regresión lineal\n",
    "def train_test_error(feature_cols, target):\n",
    "    X = data_caba_clean[feature_cols]\n",
    "    y = data_caba_clean[target].values.ravel()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=10)\n",
    "    \n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_pred = linreg.predict(X_test)\n",
    "    \n",
    "#   print (feature_cols)\n",
    "#   print (\"y_test sample: \",y_test.values[0:10])\n",
    "#   print (\"y_test sample: \",y_test)\n",
    "#   print (\"y_pred sample: \",y_pred[0:20].astype(int))\n",
    "#   print ('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "#   print ('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print ('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print ('R2:', metrics.r2_score(y_test, y_pred))\n",
    "    graf_lineal_model(X, y_test, y_pred)\n",
    "    return \n",
    "\n",
    "def train_test_error_lasso(feature_cols, target):\n",
    "    X = data_caba_clean[feature_cols]\n",
    "    y = data_caba_clean[target].values.ravel()\n",
    "    \n",
    "#   cv = KFold(5, shuffle=True)\n",
    "    cv = 3\n",
    "    # OJO que no trabajamos con tiempo por lo tanto debe ser shuffle=True.\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)\n",
    "    \n",
    "    model = linear_model.LassoCV(alphas=np.linspace(0.00001,0.1, 1000), normalize=True).fit(X_train, y_train)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "    \n",
    "    y_pred = model.predict(X_train)\n",
    "    print(dict(alpha=model.alpha_, scores=scores, mean_score=scores.mean(), zero_coefs=(model.coef_ == 0).sum()))\n",
    "    print (\"r^2:\", model.score(X, y))\n",
    "    print (\"Imprime Alpha\", model.alpha_)\n",
    "    graf_lineal_model(X, y_train, y_pred)\n",
    "    return \n",
    "\n",
    "def train_test_error_ridge(feature_cols, target):\n",
    "    X = data_caba_clean[feature_cols]\n",
    "    y = data_caba_clean[target].values.ravel()\n",
    "    \n",
    "#   cv = KFold(5, shuffle=True)\n",
    "    cv = 3\n",
    "    # OJO que no trabajamos con tiempo por lo tanto debe ser shuffle=True.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)\n",
    "    \n",
    "    #model = linear_model.Ridge(alpha=0.5, normalize=True).fit(X_train, y_train)\n",
    "    model = linear_model.RidgeCV(alphas=np.linspace(0.00001,0.1, 1000), normalize=True).fit(X_train, y_train)#agr\n",
    "    \n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "    \n",
    "    y_pred = model.predict(X_train)\n",
    "    print(dict(alpha=model.alpha_, scores=scores, mean_score=scores.mean(), zero_coefs=(model.coef_ == 0).sum()))\n",
    "    print (\"r^2:\", model.score(X, y))\n",
    "    print (\"Coeficientes de la regresión\", model.coef_)\n",
    "    graf_lineal_model(X, y_train, y_pred)\n",
    "    return \n",
    "\n",
    "def train_test_error_elastic(feature_cols, target):\n",
    "    X = data_caba_clean[feature_cols]\n",
    "    y = data_caba_clean[target].values.ravel()\n",
    "#     cv = KFold(5, shuffle=True)\n",
    "    cv = 3\n",
    "    # OJO que no trabajamos con tiempo por lo tanto debe ser shuffle=True.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)\n",
    "    \n",
    "    model = linear_model.ElasticNetCV(l1_ratio = 1, max_iter=3000, normalize=True).fit(X_train, y_train)\n",
    "    \n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "    \n",
    "    y_pred = model.predict(X_train)\n",
    "    print(dict(alpha=model.alpha_, scores=scores, mean_score=scores.mean(), zero_coefs=(model.coef_ == 0).sum()))\n",
    "    print (\"r^2:\", model.score(X, y))\n",
    "    print (\"Coeficientes de la regresión\", model.coef_)\n",
    "    graf_lineal_model(X, y_train, y_pred)\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_variables\"></a> \n",
    "<h3>Variables</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armamos objetos con las listas de variables cualitativas para poder utilizarlas más económicamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_caba_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols_places = list(place_name_dummies.columns)\n",
    "feature_cols_prop = list(property_type_dummies.columns)\n",
    "feature_cols_labels = list(m2_labels_dummies.columns)\n",
    "feature_cols_rooms = list(rooms_dummies.columns)\n",
    "# feature_cols = ['price_aprox_usd','surface_covered_in_m2','surface_total_in_m2',\n",
    "#                'pool', 'laundry', 'parking', 'gym']\n",
    "\n",
    "target = ['price_usd_per_m2']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_test1\"></a> \n",
    "<h3>Primeras pruebas de regresión simple y múltiple</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresion lineal Simple\n",
    "feature_cols = ['price_aprox_usd']\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['surface_covered_in_m2']\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregamos algunas variables cuantitativas y pobamos distintas combinaciones\n",
    "feature_cols = ['price_aprox_usd', 'surface_covered_in_m2', 'surface_total_in_m2']\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['price_aprox_usd', 'surface_covered_in_m2', 'surface_total_in_m2', 'rooms']\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2',\n",
    "                'pool', 'laundry', 'parking', 'gym']\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregamos las dummies de place_name como variables\n",
    "feature_cols.extend(feature_cols_places)\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['surface_covered_in_m2']\n",
    "feature_cols.extend(feature_cols_places)\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agregamos también el tipo de propiedad\n",
    "feature_cols.extend(feature_cols_prop)\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que al agregar más variables mejora un poco el resultado del R2 (ya no es negativo) pero de todas maneras es muy bajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_test_lasso1\"></a> \n",
    "<h3>Pruebas con modelo Lasso</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2',\n",
    "                'pool', 'laundry', 'parking', 'gym']\n",
    "train_test_error_lasso(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols.extend(feature_cols_places) \n",
    "train_test_error_lasso(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_cols = ['price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2',\n",
    "#                 'pool', 'laundry', 'parking', 'gym', 'place_name_Puerto Madero']\n",
    "# train_test_error_lasso(feature_cols, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_outliers\"></a> \n",
    "<h3>Definción de outliers</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de estas pruebas, notamos que es necesario definir y eliminar Outiliers tanto en el target como en algunas de las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Price_usd_per_m2</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bp = ax.boxplot(data_caba_clean['price_usd_per_m2'].dropna(), vert=False, showmeans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico de distribución de la variable target antes de eliminar datos extremos\n",
    "plt.hist(data_caba_clean.price_usd_per_m2, bins=20, rwidth=0.8, color = '#29788E')\n",
    "plt.title('Distribución de Precio por M2')\n",
    "plt.xlabel('Precio por M2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos outliers aproximados\n",
    "lower_bound = 0.01\n",
    "upper_bound = 0.96\n",
    "rest = data_caba_clean.price_usd_per_m2.quantile([lower_bound, upper_bound])\n",
    "rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una mask entendiendo que los precios minimos y maximos pueden rondar los 600 USD y 4000 USD y fijamos outliers aproximados\n",
    "\n",
    "precioxm2_mask = (data_caba_clean.price_usd_per_m2 >= rest[0.01]) & (data_caba_clean.price_usd_per_m2 <= rest[0.96])\n",
    "data_caba_clean = data_caba_clean.loc[precioxm2_mask, :]\n",
    "\n",
    "# Volvemos a graficar\n",
    "\n",
    "plt.hist(data_caba_clean.price_usd_per_m2, bins=20, rwidth=0.8, color = '#29788E')\n",
    "plt.title('Distribución de Precio por M2')\n",
    "plt.xlabel('Precio por M2')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(data_caba_clean.price_usd_per_m2.max()) \n",
    "print(data_caba_clean.price_usd_per_m2.min())\n",
    "\n",
    "# Parece una distribución normal? sino fuera por los valores elevados que tenemos a partir de los 4000..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Surface_covered_in_m2</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bp = ax.boxplot(data_caba_clean['surface_covered_in_m2'].dropna(), vert=False, showmeans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafio de la distribucion de superficie antes de eliminar outliers\n",
    "plt.hist(data_caba_clean.surface_covered_in_m2, bins=20, rwidth=0.8, color = '#29788E')\n",
    "plt.title('Distribución de Superficie cubierta')\n",
    "plt.xlabel('Superficie cubierta en M2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos outliers aproximados\n",
    "lower_bound = 0.001\n",
    "upper_bound = 0.99\n",
    "rest = data_caba_clean.surface_covered_in_m2.quantile([lower_bound, upper_bound])\n",
    "rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_xm2_mask = (data_caba_clean.surface_covered_in_m2 >= rest[0.001]) & (data_caba_clean.surface_covered_in_m2 <= rest[0.99])\n",
    "data_caba_clean = data_caba_clean.loc[surface_xm2_mask, :]\n",
    "\n",
    "# Graficamos la distribución actual de superficie cubierta\n",
    "\n",
    "plt.hist(data_caba_clean.surface_covered_in_m2, bins=20, rwidth=0.8, color = '#29788E')\n",
    "plt.title('Distribución de Superficie cubierta')\n",
    "plt.xlabel('Superficie cubierta en M2')\n",
    "plt.show()\n",
    "\n",
    "print(data_caba_clean.surface_covered_in_m2.max()) \n",
    "print(data_caba_clean.surface_covered_in_m2.min())\n",
    "\n",
    "# Parece una distribución normal? sino fuera por los valores elevados que tenemos a partir de los 3500..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nuevo mapa de correlación\n",
    "X = data_caba_clean[['price_usd_per_m2','price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2',\n",
    "        'pool', 'laundry', 'parking', 'gym', 'rooms', 'place_name_Puerto Madero']]\n",
    "\n",
    "g = plt.figure(figsize=(13,10))\n",
    "g = sns.heatmap(X.corr(),annot=True, cmap=\"YlGnBu\")\n",
    "g.set_xticklabels(X.columns, rotation=45)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a definir las dummies de 'rooms' ya que cambiaron los valores de superficie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_dummies = pd.get_dummies(data_caba_clean['rooms'], drop_first = True, prefix = 'rooms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols_rooms =list(rooms_dummies.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_test2\"></a> \n",
    "<h3>Nuevas pruebas con datos ajustados</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regresión lineal simple con datos ajustados. Aún con una sola variable notamos una mejora sustancial\n",
    "feature_cols = ['price_aprox_usd']\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regresión lineal con variables base\n",
    "feature_cols = ['price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2',\n",
    "                'pool', 'laundry', 'parking', 'gym']\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regresión lineal con variables base\n",
    "feature_cols = ['price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2',\n",
    "                'pool', 'laundry', 'parking', 'gym', 'rooms']\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregamos a las features de arriba las dummies de place_name\n",
    "feature_cols.extend(feature_cols_places)\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregamos las dummies de prop_type\n",
    "feature_cols.extend(feature_cols_prop)\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prueba de Regresión lineal con todas las dummies y todas las variables\n",
    "feature_cols.extend(feature_cols_labels)\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols.extend(feature_cols_rooms)\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_test_lasso2\"></a> \n",
    "<h3>Nuevas pruebas de Modelo Lasso con datos ajustados</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2',\n",
    "                'pool', 'laundry', 'parking', 'gym']\n",
    "train_test_error_lasso(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols.extend(feature_cols_places)\n",
    "train_test_error_lasso(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols.extend(feature_cols_prop)\n",
    "train_test_error_lasso(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols.extend(feature_cols_labels)\n",
    "train_test_error_lasso(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols.extend(feature_cols_rooms)\n",
    "train_test_error_lasso(feature_cols, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados con Lasso son muy parecidos a los de las LinearRegression, pero no la mejoran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_test_ridge\"></a> \n",
    "<h3>Pruebas con modelo Ridge</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['price_aprox_usd', 'surface_covered_in_m2']\n",
    "train_test_error_ridge(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2',\n",
    "                'pool', 'laundry', 'parking', 'gym', 'rooms']\n",
    "train_test_error_ridge(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prueba de Ridge con variables base + dummies de place_name\n",
    "feature_cols.extend(feature_cols_places)\n",
    "train_test_error_ridge(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prueba de Ridge con variables base + dummies de place_name + dummies de prop_type\n",
    "feature_cols.extend(feature_cols_prop)\n",
    "train_test_error_ridge(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols.extend(feature_cols_rooms)\n",
    "train_test_error_ridge(feature_cols, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo mismo se observa con el modelo Ridge, los resultados obtenidos son muy similares, pero no mejoran el modelo inicial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_test_elastic\"></a> \n",
    "<h3>Pruebas con modelo Elastic</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['price_aprox_usd', 'surface_total_in_m2', 'surface_covered_in_m2',\n",
    "                'pool', 'laundry', 'parking', 'gym']\n",
    "train_test_error_elastic(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols.extend(feature_cols_places)\n",
    "train_test_error_elastic(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols.extend(feature_cols_prop)\n",
    "train_test_error_elastic(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols.extend(feature_cols_labels)\n",
    "train_test_error_elastic(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols.extend(feature_cols_rooms)\n",
    "train_test_error_elastic(feature_cols, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_new_features\"></a> \n",
    "<h3>Creación de features para complejizar el modelo</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos nuevas features para complejizar el modelo y testeamos nuevamente con todos los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_sup2\"></a> \n",
    "<h4>Superficie<sup>2</sup></h4>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo una nueva feature a partir de una existente para complejizar el modelo y tratar de obtener un R^2 más elevado\n",
    "data_caba_clean['surface_covered_in_m2_2']=data_caba_clean['surface_covered_in_m2']**2\n",
    "data_caba_clean['surface_covered_in_m2_3']=data_caba_clean['surface_covered_in_m2']**3\n",
    "data_caba_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tomo las nueva feature 'surface_covered_in_m2_2'\n",
    "X = data_caba_clean[['price_usd_per_m2','price_aprox_usd', 'surface_total_in_m2','pool', 'laundry', 'parking', 'gym',\n",
    "                     'surface_covered_in_m2_2','surface_covered_in_m2']]\n",
    "\n",
    "plt.figure(figsize=(13,10))\n",
    "sns.heatmap(X.corr(),annot=True)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['price_aprox_usd', 'surface_total_in_m2','pool', 'laundry', 'parking', 'gym',\n",
    "                'surface_covered_in_m2','surface_covered_in_m2_2']\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['price_aprox_usd', 'surface_total_in_m2','pool', 'laundry', 'parking', 'gym',\n",
    "                'surface_covered_in_m2','surface_covered_in_m2_2']\n",
    "train_test_error_lasso(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['price_aprox_usd', 'surface_total_in_m2','pool', 'laundry', 'parking', 'gym',\n",
    "                'surface_covered_in_m2','surface_covered_in_m2_2']\n",
    "train_test_error_ridge(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pruebo con todas las features y con la creada surface_covered_in_m2_2\n",
    "feature_cols.extend(feature_cols_places)\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols.extend(feature_cols_prop)\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_error_lasso(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_error_ridge(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_error_elastic(feature_cols, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_sup3\"></a> \n",
    "<h4>Superficie<sup>3</sup></h4>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrego una nueva feature ('surface_covered_in_m2_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_caba_clean[['price_usd_per_m2','price_aprox_usd', 'surface_total_in_m2','pool', 'laundry', 'parking', 'gym',\n",
    "                     'surface_covered_in_m2_2','surface_covered_in_m2','surface_covered_in_m2_3']]\n",
    "\n",
    "plt.figure(figsize=(13,10))\n",
    "sns.heatmap(X.corr(),annot=True)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['price_aprox_usd', 'surface_total_in_m2','pool', 'laundry', 'parking', 'gym',\n",
    "                'surface_covered_in_m2','surface_covered_in_m2_2','surface_covered_in_m2_3']\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['price_aprox_usd', 'surface_total_in_m2','pool', 'laundry', 'parking', 'gym',\n",
    "                'surface_covered_in_m2','surface_covered_in_m2_2','surface_covered_in_m2_3']\n",
    "train_test_error_lasso(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['price_aprox_usd', 'surface_total_in_m2','pool', 'laundry', 'parking', 'gym',\n",
    "                'surface_covered_in_m2','surface_covered_in_m2_2','surface_covered_in_m2_3']\n",
    "train_test_error_ridge(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con todas las features\n",
    "feature_cols.extend(feature_cols_places)\n",
    "feature_cols.extend(feature_cols_prop)\n",
    "feature_cols.extend(feature_cols_rooms)\n",
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_error_lasso(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_error_ridge(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_error_elastic(feature_cols, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_total_price_estimate\"></a> \n",
    "<h3>Estimación de precio total utilizando el mismo modelo</h3>\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['surface_covered_in_m2','surface_total_in_m2',\n",
    "                'pool', 'laundry', 'parking', 'gym', 'rooms']\n",
    "feature_cols.extend(feature_cols_places)\n",
    "feature_cols.extend(feature_cols_prop)\n",
    "feature_cols.extend(feature_cols_labels)\n",
    "feature_cols.extend(feature_cols_rooms)\n",
    "\n",
    "target = ['price_aprox_usd']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_error(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_error_elastic(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_error_lasso(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_error_ridge(feature_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
